{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-hyEhoxqqG3",
        "outputId": "7037322b-a894-4b3e-84d0-6dff6cd071fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ram', 'is', 'a', 'good', 'boy']\n"
          ]
        }
      ],
      "source": [
        "## basics without ml\n",
        "text =\"Ram is a good boy\"\n",
        "print(text.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## NLP\n",
        "## libarabry to use -- !pip install nltk, spacy\n",
        "!pip install nltk spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNNrq5POrI6c",
        "outputId": "da5f8f42-9809-4e84-aa78-3db9a2a11d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "\n",
        "\n",
        "text =\"Ram is a good boy. he loves to play football\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdR4LZA5rqyp",
        "outputId": "2374d880-ca47-4ebd-a1e5-ed32e9cfc05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ram is a good boy.', 'he loves to play football']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text =\"Suraj is playing cricket. he is good at it\"\n",
        "words =word_tokenize(text)\n",
        "print (words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7oeBfdTt_JY",
        "outputId": "6a309ac1-58ea-42c4-c7ad-f90c09b143b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Suraj', 'is', 'playing', 'cricket', '.', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## same work with spacy liabrary\n",
        "### SPACY ##\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(text) ## documnet gets converted to spacy format\n",
        "sentences = [sent.text for sent in doc.sents] ## list comprehension\n",
        "\n",
        "\n",
        "print(sentences)\n",
        "print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89MZtOamuGAh",
        "outputId": "b8c74d62-f099-439e-da78-e5bbe304e2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Suraj is playing cricket.', 'he is good at it']\n",
            "Suraj is playing cricket. he is good at it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [token.text for token in doc]\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQdWuVLvAE3",
        "outputId": "05c37bff-75ee-4a4e-d420-fa530b97cb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Suraj', 'is', 'playing', 'cricket', '.', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##removing punctaution\n",
        "import string\n",
        "##no_punc_text = text.translate(str('','',string.punctuation))\n",
        "text =\"Suraj is playing cricket. he is good at it\"\n",
        "words =word_tokenize(text)\n",
        "\n",
        "no_punct = [i for i in words if i not in string.punctuation]\n",
        "print(no_punct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwxGwEDCxv_3",
        "outputId": "1f660256-d8ea-4b39-851b-99077823e95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## casing\n",
        "\n",
        "lower_case = [words.lower() for words in no_punct]\n",
        "print(lower_case)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG9x0-6r1gFt",
        "outputId": "154adb6e-1139-4e74-ab2e-9372a5aa4244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Stemmimng and lemitizing\n",
        "## reducing a word to its base form\n",
        "\n",
        "## tool- porterstemmer/lancasterStemmer (differenec is accuracy ) porterstemmer is better\n",
        "## same with lemitization but its more accurate\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed =[stemmer.stem(word) for word in lower_case]\n",
        "\n",
        "print(\"Lower Cased -\",lower_case)\n",
        "print(\"Stemmed -\",stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0__tS-k1t1sn",
        "outputId": "d61a8b2b-4f39-49df-ee9c-4d96df2d49a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower Cased - ['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n",
            "Stemmed - ['suraj', 'is', 'play', 'cricket', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rw_g-Sbhw2_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "Lemitize = WordNetLemmatizer()\n",
        "lemitized = [Lemitize.lemmatize(word) for word in lower_case ]\n",
        "print(\"Lower Cased -\",lower_case)\n",
        "print(\"Lemitized - \",lemitized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ea2c49-6b1c-4503-b3eb-f18bbf3dd0c6",
        "id": "O9kQ3XSKxSZh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower Cased - ['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n",
            "Lemitized -  ['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk.stem as  WordNetLemmatizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "\n",
        "lower_case = [words.lower() for words in no_punct]\n",
        "print(lower_case)\n",
        "\n",
        "Lemitize = WordNetLemmatizer()\n",
        "\n",
        "Lemitized = [Lemitize.lemmatize(word) for word in lower_case ]\n",
        "print(\"Lemitized - \",Lemitized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdS7b-0hvyC2",
        "outputId": "2d2ffc7d-0528-423b-af72-85c2e21f25ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n",
            "Lemitized -  ['suraj', 'is', 'playing', 'cricket', 'he', 'is', 'good', 'at', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "f03ez_ZUx80j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data ={'text':[\"The cats are running faster than the dogs\",\n",
        "              \"He was playing football and studying mathematics\",\n",
        "               \"l love natural language Processing\"]\n",
        "\n",
        "\n",
        "\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print (df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMIn418Dyfow",
        "outputId": "f23ed2dc-dc3e-4337-90d7-b617693c497b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               text\n",
            "0         The cats are running faster than the dogs\n",
            "1  He was playing football and studying mathematics\n",
            "2                l love natural language Processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "Lemmmatizer = WordNetLemmatizer()\n",
        "\n",
        "def pre_process_text(text):\n",
        "  tokens=word_tokenize(text)\n",
        "\n",
        "  ##punctuation\n",
        "  no_punct = [i for i in tokens if i not in string.punctuation]\n",
        "\n",
        "## lowr case\n",
        "  lower_case = [word.lower() for word in no_punct]\n",
        "\n",
        "##lemitizing\n",
        "  lemmitized = [Lemmmatizer.lemmatize(word) for word in lower_case]\n",
        "\n",
        "##stemming\n",
        "  stemmed = [stemmer.stem(word) for word in lower_case]\n",
        "\n",
        "  return lemmitized"
      ],
      "metadata": {
        "id": "IPNYqS7k9RlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = df['text'].apply(pre_process_text)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p--ZpfC1Iy7H",
        "outputId": "7adc6b27-d9ac-47a0-a37e-1c2e708cf083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     [the, cat, are, running, faster, than, the, dog]\n",
            "1    [he, wa, playing, football, and, studying, mat...\n",
            "2             [l, love, natural, language, processing]\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    }
  ]
}